# TableChat Environment Configuration (简化版架构)
# ============================================================================
# 所有 LLM 请求统一通过 claude-code-proxy 代理
# ============================================================================

# ============================================================================
# 应用配置（后端连接 proxy）
# ============================================================================

# API Key（必填 - 这个 key 用于 proxy 认证，会传给上游服务）
LLM_API_KEY=your-api-key

# 模型名称
# - Anthropic 模式: claude-sonnet-4-5-20250929
# - OpenAI 模式: 需要 openai/ 前缀，如 openai/qwen/qwen3-4b-2507
LLM_MODEL=claude-sonnet-4-5-20250929

# ============================================================================
# Proxy 上游配置（proxy 连接的后端服务）
# ============================================================================

# 上游 API 类型: "anthropic" (默认) 或 "openai"
# - anthropic: 连接 Anthropic API 或兼容服务
# - openai: 连接 OpenAI API 或兼容服务（如 vLLM、LM Studio、Ollama）
UPSTREAM_API_TYPE=anthropic

# 上游 API 地址（根据类型自动选择默认值）
# - Anthropic: https://api.anthropic.com
# - OpenAI: https://api.openai.com/v1
# UPSTREAM_API_BASE=https://api.anthropic.com

# 上游 API Key（可选，如果和 LLM_API_KEY 不同）
# UPSTREAM_API_KEY=your-upstream-key

# ============================================================================
# Agent 配置（可选调优）
# ============================================================================

# Agent 最大交互轮次 (默认: 20)
# AGENT_MAX_TURNS=20

# Agent 超时时间（秒，默认: 120）
# AGENT_TIMEOUT=120

# ============================================================================
# 数据库配置
# ============================================================================

# SQLite 数据库路径（Docker: /app/data/scinew.db, 本地: ./scinew.db）
DATABASE_PATH=/app/data/scinew.db

# PostgreSQL 连接超时（秒）
PG_CONNECT_TIMEOUT=10

# MySQL 连接超时（秒）
MYSQL_CONNECT_TIMEOUT=10

# ============================================================================
# 服务器配置
# ============================================================================

# HOST=0.0.0.0
# PORT=7888
# DEBUG=false

# ============================================================================
# 配置示例
# ============================================================================

# 示例 1: 使用 Anthropic API（默认，推荐）
# LLM_API_KEY=sk-ant-xxxxx
# UPSTREAM_API_TYPE=anthropic

# 示例 2: 使用 OpenAI 兼容服务（如 LM Studio）
# LLM_API_KEY=lm-studio
# UPSTREAM_API_TYPE=openai
# UPSTREAM_API_BASE=http://192.168.31.25:1234/v1
# LLM_MODEL=openai/qwen/qwen3-4b-2507  # ⚠️ 注意 openai/ 前缀

# 示例 3: 使用 vLLM 部署
# LLM_API_KEY=your-key
# UPSTREAM_API_TYPE=openai
# UPSTREAM_API_BASE=http://your-vllm-server:8000/v1
# LLM_MODEL=openai/Qwen/Qwen2.5-72B-Instruct  # ⚠️ 注意 openai/ 前缀

# 示例 4: 使用自定义 Anthropic 兼容代理
# LLM_API_KEY=your-proxy-key
# UPSTREAM_API_TYPE=anthropic
# UPSTREAM_API_BASE=http://your-proxy:3000/api
